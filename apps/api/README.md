# ğŸ§¬ Whey Comparator â€” Backend FastAPI

Ce dossier contient l'API qui alimente la plateforme FitIdion. Elle centralise les offres collectÃ©es (scraping, sources partenaires), calcule les historiques de prix et orchestre les workflows d'alertes consommÃ©s par le frontend Next.js et des intÃ©grations tierces.

## ğŸ—‚ï¸ Architecture du dossier

```
apps/api/
â”œâ”€â”€ README.md                     # Ce guide backend
â”œâ”€â”€ pyproject.toml                # DÃ©pendances Poetry (FastAPI, SQLAlchemy, Celery, APSchedulerâ€¦)
â”œâ”€â”€ alembic.ini                   # Config migrations Alembic
â”œâ”€â”€ alembic/                      # Scripts de migration (versions gÃ©nÃ©rÃ©es)
â”œâ”€â”€ tests/                        # Suite Pytest + HTTPX
â”‚   â”œâ”€â”€ conftest.py               # Fixtures (client FastAPI, session DB en mÃ©moire)
â”‚   â”œâ”€â”€ test_products.py          # Tests CRUD produits & historique de prix
â”‚   â”œâ”€â”€ test_offers.py            # Tests CRUD offres + filtres
â”‚   â””â”€â”€ test_price_alerts.py      # Tests crÃ©ation/mise Ã  jour des alertes
â””â”€â”€ app/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ main.py                   # Application FastAPI + middlewares + montage routers
    â”œâ”€â”€ config.py                 # ParamÃ©trage Pydantic Settings (prÃ©fixe `API_`)
    â”œâ”€â”€ database.py               # Session SQLAlchemy + Base declarative + dÃ©pendance `get_db`
    â”œâ”€â”€ models.py                 # ORM (Product, Supplier, Offer, PriceHistory, PriceAlert, ScrapeJob)
    â”œâ”€â”€ schemas.py                # ModÃ¨les Pydantic v2 (lecture/Ã©criture + pagination standardisÃ©e)
    â”œâ”€â”€ routers/
    â”‚   â”œâ”€â”€ products.py           # Endpoints `/products` + `/products/{id}/price-history`
    â”‚   â”œâ”€â”€ offers.py             # Endpoints `/offers`
    â”‚   â”œâ”€â”€ suppliers.py          # Endpoints `/suppliers`
    â”‚   â””â”€â”€ price_alerts.py       # Endpoints `/price-alerts`
    â”œâ”€â”€ celery_app.py             # Initialisation Celery (broker/result Redis)
    â”œâ”€â”€ tasks.py                  # TÃ¢ches Celery (scraping simulÃ©, traitement alertes)
    â”œâ”€â”€ scheduler.py              # APScheduler pour rafraÃ®chir la collecte
    â””â”€â”€ email.py                  # Envoi dâ€™emails & gabarits de notifications
```

## âš™ï¸ Fonctionnement

1. **Application FastAPI** : `app/main.py` installe CORS, configure les middlewares (logging, `X-Request-ID`) et monte les routeurs `products`, `offers`, `suppliers`, `price_alerts` ainsi que `/health`.
2. **Couche persistence** : `database.py` fournit `SessionLocal`/`engine` et la dÃ©pendance `get_db`. `models.py` couvre `Product`, `Supplier`, `Offer`, `PriceHistory`, `PriceAlert`, `ScrapeJob` tandis que `schemas.py` expose les DTO lecture/Ã©criture et enveloppes paginÃ©es.
3. **Migrations & seed** : Alembic orchestre les Ã©volutions SQL. Les rÃ©pertoires `alembic/versions` contiennent les migrations alignÃ©es avec les modÃ¨les.
4. **TÃ¢ches asynchrones** : `celery_app.py` dÃ©clare lâ€™application Celery (Redis). `tasks.py` et `scheduler.py` alimentent le scraping, actualisent les offres et planifient les jobs rÃ©currents. `email.py` centralise lâ€™envoi des notifications dâ€™alertes.
5. **InteropÃ©rabilitÃ© frontend** : les routeurs exposent des rÃ©ponses paginÃ©es cohÃ©rentes avec le frontend Next.js. Les conversions (ratio protÃ©ines/prix, meilleure offre) sont dÃ©lÃ©guÃ©es aux schÃ©mas et au service dâ€™agrÃ©gation.

## ğŸ“š BibliothÃ¨ques principales

- **FastAPI 0.110** pour l'API REST et la documentation OpenAPI automatique.
- **SQLAlchemy 2.0** + **Pydantic v2** pour l'ORM et la validation.
- **Alembic** pour les migrations.
- **Celery 5** & **Redis 5** pour les traitements diffÃ©rÃ©s.
- **Uvicorn** (serveur ASGI) et **psycopg 3** (driver PostgreSQL).
- **python-dotenv / pydantic-settings** pour la configuration.

## âœ¨ AmÃ©liorations rÃ©centes

- Ajout de l'endpoint `GET /products/{id}/price-history` avec calcul automatique des statistiques (min/moyenne/tendance) pour les graphiques d'analyse de prix.
- Uniformisation des rÃ©ponses paginÃ©es (`PaginatedProducts`, `PaginatedOffers`, `PaginatedSuppliers`, `PaginatedPriceAlerts`) pour le thÃ¨me frontend et les intÃ©grations tierces.
- Enregistrement des jobs de scraping simulÃ©s et des alertes prix afin d'alimenter la recherche unifiÃ©e et les sections monitoring du dashboard.

## ğŸ”Œ Endpoints phares

| MÃ©thode | Route | Description |
| --- | --- | --- |
| `GET` | `/products` | Liste paginÃ©e avec filtres, ratio protÃ©ines/prix et meilleure offre associÃ©e. |
| `GET` | `/products/{id}` | DÃ©tail complet incluant nutrition, tags, offres attachÃ©es. |
| `GET` | `/products/{id}/price-history` | 30 points max + statistiques (`current`, `lowest`, `trend`). |
| `GET` | `/offers` | Filtrage multi-critÃ¨res (prix, disponibilitÃ©, marchands). |
| `GET` | `/suppliers` | RÃ©fÃ©rentiel marchands & URLs d'affiliation. |
| `POST` | `/price-alerts` | CrÃ©ation d'une alerte (email + seuil) synchronisÃ©e avec le worker Celery. |
| `PATCH` | `/price-alerts/{id}` | Activation/dÃ©sactivation et mise Ã  jour du seuil cible. |

Les payloads Pydantic sont disponibles dans `app/schemas.py`. Une vue d'ensemble (API d'orchestration + agrÃ©gation) est dÃ©crite dans `../../docs/api_endpoints.md`.

## ğŸ“¦ DÃ©pendances & installation

Le backend est gÃ©rÃ© via [Poetry](https://python-poetry.org/).

```bash
cd apps/api
poetry install
```

Un fichier `poetry.lock` est gÃ©nÃ©rÃ© automatiquement. Les dÃ©pendances clÃ©s sont listÃ©es dans `pyproject.toml` (FastAPI, SQLAlchemy, Alembic, Celery, Redis, psycopg, pytest...).

## ğŸ” Variables d'environnement

Les paramÃ¨tres se chargent via `API_` (voir `config.py`). Exemple `.env` :

| Variable | Description | Valeur par dÃ©faut |
| --- | --- | --- |
| `API_DATABASE_URL` | ChaÃ®ne de connexion PostgreSQL/SQLAlchemy | `postgresql+psycopg://postgres:postgres@db:5432/whey` |
| `API_ALEMBIC_INI` | Chemin vers le fichier Alembic | `alembic.ini` |
| `API_CELERY_BROKER_URL` | Broker Celery (Redis recommandÃ©) | `redis://redis:6379/0` |
| `API_CELERY_RESULT_BACKEND` | Backend de rÃ©sultats Celery | `redis://redis:6379/0` |

Pour exÃ©cuter localement :

```bash
poetry run uvicorn app.main:app --reload
poetry run celery -A app.tasks.celery_app worker -l info
```

## ğŸ› ï¸ Fonctionnement quotidien

- `GET /products` accepte les filtres `search`, `sort_by`, `sort_order`, `limit`, `offset`, `min_price`, `max_price`.
- `GET /offers` ajoute `product_id`, `supplier_id`, `available`, `currency`.
- `GET /suppliers` supporte la recherche texte (`name`, `website`).
- `GET /products/{id}/price-history` expose un historique consolidÃ© pour alimenter les graphiques Recharts.
- `POST /price-alerts` et `PATCH /price-alerts/{id}` gÃ¨rent l'activation des notifications cÃ´tÃ© utilisateur.
- Toutes les routes CRUD sont documentÃ©es sur `/docs` (Swagger UI) une fois le serveur lancÃ©.

## ğŸ›£ï¸ Roadmap backend

- [ ] Finaliser l'intÃ©gration rÃ©elle des scrapers (remplacer la simulation Celery).
- [ ] Ajouter des agrÃ©gations prix/volume (rapport protÃ©ine â‚¬/kg) pour la nouvelle UI analytique.
- [ ] Mettre en place l'authentification API key pour les partenaires.
- [ ] Couvrir les routes CRUD par des tests Pytest supplÃ©mentaires (cas d'erreurs, permissions futures).
- [ ] Automatiser les migrations dans le pipeline CI/CD.
