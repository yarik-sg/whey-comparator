# ğŸ§¬ Whey Comparator â€” Backend FastAPI

Ce dossier contient l'API qui alimente le comparateur de complÃ©ments alimentaires. Elle centralise les offres collectÃ©es (scraping, sources partenaires) et expose des routes REST pour le frontend Next.js ainsi que pour des intÃ©grations tierces.

## ğŸ—‚ï¸ Architecture du dossier

```
apps/api/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # Initialisation FastAPI + middlewares
â”‚   â”œâ”€â”€ config.py            # Chargement des variables d'environnement (prÃ©fixe API_)
â”‚   â”œâ”€â”€ database.py          # Session SQLAlchemy + gestion du moteur
â”‚   â”œâ”€â”€ models.py            # ModÃ¨les ORM (Product, Supplier, Offer, ScrapeJob)
â”‚   â”œâ”€â”€ schemas.py           # SchÃ©mas Pydantic v2 pour les payloads/retours
â”‚   â”œâ”€â”€ routers/             # Routes REST (products, suppliers, offers)
â”‚   â”œâ”€â”€ celery_app.py        # Configuration Celery (broker/result Redis)
â”‚   â””â”€â”€ tasks.py             # TÃ¢ches d'ingestion & scraping simulÃ©
â”œâ”€â”€ alembic/                 # Scripts de migrations
â”œâ”€â”€ alembic.ini              # Configuration Alembic
â”œâ”€â”€ tests/                   # Jeux de tests Pytest + HTTPX
â””â”€â”€ pyproject.toml           # DÃ©pendances Poetry
```

## âš™ï¸ Fonctionnement

1. **Application FastAPI** : `app/main.py` installe CORS et monte les routeurs `products`, `suppliers`, `offers` et la route de healthcheck. Chaque route renvoie des schÃ©mas Pydantic typÃ©s (pagination incluse).
2. **AccÃ¨s base de donnÃ©es** : `database.py` expose `SessionLocal` et une dÃ©pendance `get_db` pour injecter une session SQLAlchemy dans les routes. Les modÃ¨les couvrent produits, fournisseurs, offres et historiques de scraping.
3. **Migrations & data lifecycle** : Alembic gÃ¨re la structure SQL. Les mises Ã  jour CRUD se propagent via SQLAlchemy avec rafraÃ®chissement automatique.
4. **TÃ¢ches asynchrones** : `celery_app.py` configure Celery (Redis). Le module `tasks.py` simule une exÃ©cution de scraping, alimente la table `scrape_jobs` et stocke les logs horodatÃ©s.
5. **InteropÃ©rabilitÃ© frontend** : les routes paginÃ©es et filtrables exposent les mÃªmes champs que consommÃ©s par l'App Router (rÃ©sumÃ©s produits, offres filtrÃ©es, listes de marchands).

## ğŸ“š BibliothÃ¨ques principales

- **FastAPI 0.110** pour l'API REST et la documentation OpenAPI automatique.
- **SQLAlchemy 2.0** + **Pydantic v2** pour l'ORM et la validation.
- **Alembic** pour les migrations.
- **Celery 5** & **Redis 5** pour les traitements diffÃ©rÃ©s.
- **Uvicorn** (serveur ASGI) et **psycopg 3** (driver PostgreSQL).
- **python-dotenv / pydantic-settings** pour la configuration.

## âœ¨ AmÃ©liorations rÃ©centes

- Exposition d'une pagination homogÃ¨ne (`PaginatedProducts`, `PaginatedOffers`, `PaginatedSuppliers`) consommÃ©e par le nouveau thÃ¨me frontend.
- Ajout des routes `offers` et `suppliers` avec filtres multi-critÃ¨res pour alimenter les nouvelles sections comparateur & partenaires.
- Enregistrement des jobs de scraping simulÃ©s pour accompagner la refonte UI (vignettes d'activitÃ©, logs).

## ğŸ“¦ DÃ©pendances & installation

Le backend est gÃ©rÃ© via [Poetry](https://python-poetry.org/).

```bash
cd apps/api
poetry install
```

Un fichier `poetry.lock` est gÃ©nÃ©rÃ© automatiquement. Les dÃ©pendances clÃ©s sont listÃ©es dans `pyproject.toml` (FastAPI, SQLAlchemy, Alembic, Celery, Redis, psycopg, pytest...).

## ğŸ” Variables d'environnement

Les paramÃ¨tres se chargent via `API_` (voir `config.py`). Exemple `.env` :

| Variable | Description | Valeur par dÃ©faut |
| --- | --- | --- |
| `API_DATABASE_URL` | ChaÃ®ne de connexion PostgreSQL/SQLAlchemy | `postgresql+psycopg://postgres:postgres@db:5432/whey` |
| `API_ALEMBIC_INI` | Chemin vers le fichier Alembic | `alembic.ini` |
| `API_CELERY_BROKER_URL` | Broker Celery (Redis recommandÃ©) | `redis://redis:6379/0` |
| `API_CELERY_RESULT_BACKEND` | Backend de rÃ©sultats Celery | `redis://redis:6379/0` |

Pour exÃ©cuter localement :

```bash
poetry run uvicorn app.main:app --reload
poetry run celery -A app.tasks.celery_app worker -l info
```

## ğŸ› ï¸ Fonctionnement quotidien

- `GET /products` accepte filtres `search`, `sort_by`, `sort_order`, `limit`, `offset`.
- `GET /offers` ajoute `product_id`, `supplier_id`, `min_price`, `max_price`, `available`.
- `GET /suppliers` supporte la recherche texte (`name`, `website`).
- CRUD complet pour chaque ressource + `GET /health`.

Consultez `/docs` (Swagger UI) une fois le serveur lancÃ©.

## ğŸ›£ï¸ Roadmap backend

- [ ] Finaliser l'intÃ©gration rÃ©elle des scrapers (remplacer la simulation Celery).
- [ ] Ajouter des agrÃ©gations prix/volume (rapport protÃ©ine â‚¬/kg) pour la nouvelle UI analytique.
- [ ] Mettre en place l'authentification API key pour les partenaires.
- [ ] Couvrir les routes CRUD par des tests Pytest supplÃ©mentaires (cas d'erreurs, permissions futures).
- [ ] Automatiser les migrations dans le pipeline CI/CD.
