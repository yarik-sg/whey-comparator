# ğŸ—ï¸ Whey-Comparator - Architecture & Feuille de Route

## ğŸ“‹ Vue d'Ensemble du Projet

**Whey-Comparator** est une application web React/Vite permettant aux utilisateurs de comparer les prix et caractÃ©ristiques des supplÃ©ments alimentaires (protÃ©ines, crÃ©atine, etc.) Ã  travers plusieurs plateformes e-commerce.

---

## âš™ï¸ Variables d'Environnement

### Backend (FastAPI â€“ `main.py`)

- `SERPAPI_KEY` : clÃ© API SerpAPI utilisÃ©e pour interroger Google Shopping.
- `SCRAPER_BASE_URL` : URL de base du service scraper FastAPI (`services/scraper`) exposant `/products` et `/products/{id}/offers`.
- `API_BASE_URL` *(optionnel)* : URL publique de l'API principale (utile pour les appels cÃ´tÃ© serveur du frontend).

### Frontend (Next.js â€“ `frontend/`)

- `NEXT_PUBLIC_API_BASE_URL` : URL publique utilisÃ©e dans le navigateur pour atteindre l'API FastAPI.
- `API_BASE_URL` *(optionnel)* : fallback cÃ´tÃ© serveur (App Router) si `NEXT_PUBLIC_API_BASE_URL` n'est pas dÃ©fini.

Toutes les requÃªtes front passent par `frontend/src/lib/apiClient.ts` qui injecte automatiquement ces URLs et gÃ¨re la sÃ©rialisation JSON.

---

## ğŸ”„ Flux de DonnÃ©es Temps RÃ©el

1. **Collecte** : le service scraper (`services/scraper`) agrÃ¨ge en continu les offres Amazon/MyProtein/Google Shopping et les persiste (PostgreSQL).
2. **Enrichissement Ã  la demande** : `main.py` combine ces donnÃ©es persistÃ©es avec les rÃ©sultats temps rÃ©el SerpAPI via les endpoints `/compare`, `/products`, `/products/{id}/offers` et `/comparison`.
3. **Diffusion** : le frontend consomme ces endpoints via le client API partagÃ©, met en cache cÃ´tÃ© React et affiche les meilleures offres avec recalcul du Â« best price Â».
4. **Pages dÃ©diÃ©es** :
   - `/products` liste le catalogue issu du scraper.
   - `/products/{id}` fusionne offres persistÃ©es et SerpAPI pour un produit.
   - `/comparison` compare plusieurs IDs (query `ids=1,2,3`).
   - `/comparateur` dÃ©clenche des recherches dynamiques sur `/compare` Ã  partir dâ€™un mot-clÃ©.

Cette chaÃ®ne permet de dÃ©clencher des comparaisons quasi temps rÃ©el tout en capitalisant sur l'historique du scraper.

---


## ğŸ¯ Architecture Globale

### Stack Technique RecommandÃ©e

#### **Frontend**
- **Framework**: React 18+ avec Vite
- **Routing**: React Router v6
- **State Management**: 
  - React Context API (Ã©tat global lÃ©ger)
  - TanStack Query (React Query) pour le cache et les requÃªtes API
- **Styling**: 
  - Tailwind CSS (dÃ©jÃ  configurÃ© avec Vite)
  - shadcn/ui pour les composants UI
- **Graphiques**: Recharts pour les comparaisons de prix
- **Formulaires**: React Hook Form + Zod pour la validation

#### **Backend/API Layer**
- **Option 1 (RecommandÃ©e)**: Backend Node.js sÃ©parÃ©
  - Express.js ou Fastify
  - API RESTful ou GraphQL
  - Base de donnÃ©es: PostgreSQL (produits) + Redis (cache)
  
- **Option 2**: Backend-as-a-Service
  - Supabase (PostgreSQL + Auth + Storage)
  - Vercel Edge Functions pour le scraping

#### **Data Collection (Scraping)**
- **Node.js** avec:
  - Puppeteer/Playwright (scraping JavaScript)
  - Cheerio (parsing HTML)
  - Axios (requÃªtes HTTP simples)
- **Cron Jobs** pour mises Ã  jour automatiques
- **Queue System**: Bull/BullMQ pour gÃ©rer les tÃ¢ches de scraping

---

## ğŸ—‚ï¸ Structure de Projet RecommandÃ©e

```
whey-comparator/
â”œâ”€â”€ frontend/                    # Application React
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ ui/             # Composants shadcn/ui
â”‚   â”‚   â”‚   â”œâ”€â”€ products/       # Composants liÃ©s aux produits
â”‚   â”‚   â”‚   â”œâ”€â”€ comparison/     # Composants de comparaison
â”‚   â”‚   â”‚   â””â”€â”€ layout/         # Layout, Header, Footer
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ Home.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ProductList.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ProductDetail.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Comparison.jsx
â”‚   â”‚   â”‚   â””â”€â”€ About.jsx
â”‚   â”‚   â”œâ”€â”€ hooks/              # Custom hooks
â”‚   â”‚   â”œâ”€â”€ services/           # API calls
â”‚   â”‚   â”œâ”€â”€ utils/              # Fonctions utilitaires
â”‚   â”‚   â”œâ”€â”€ contexts/           # React contexts
â”‚   â”‚   â”œâ”€â”€ types/              # TypeScript types
â”‚   â”‚   â””â”€â”€ App.jsx
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.js
â”‚
â”œâ”€â”€ backend/                     # API Backend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ controllers/        # Logique mÃ©tier
â”‚   â”‚   â”œâ”€â”€ models/             # ModÃ¨les de donnÃ©es
â”‚   â”‚   â”œâ”€â”€ routes/             # Routes API
â”‚   â”‚   â”œâ”€â”€ services/           # Services (scraping, etc.)
â”‚   â”‚   â”œâ”€â”€ middleware/         # Middlewares Express
â”‚   â”‚   â”œâ”€â”€ config/             # Configuration
â”‚   â”‚   â””â”€â”€ server.js
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ .env
â”‚
â”œâ”€â”€ scrapers/                    # Modules de scraping
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ scrapers/
â”‚   â”‚   â”‚   â”œâ”€â”€ myprotein.js
â”‚   â”‚   â”‚   â”œâ”€â”€ prozis.js
â”‚   â”‚   â”‚   â”œâ”€â”€ amazon.js
â”‚   â”‚   â”‚   â””â”€â”€ base-scraper.js
â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ queue/              # Bull queue configuration
â”‚   â”‚   â””â”€â”€ index.js
â”‚   â””â”€â”€ package.json
â”‚
â””â”€â”€ shared/                      # Code partagÃ©
    â”œâ”€â”€ types/                   # Types TypeScript partagÃ©s
    â””â”€â”€ constants/               # Constantes partagÃ©es
```

---

## ğŸ—„ï¸ ModÃ¨le de DonnÃ©es

### **Product**
```javascript
{
  id: string,
  name: string,
  brand: string,
  category: 'whey' | 'casein' | 'creatine' | 'bcaa' | 'other',
  type: string, // 'isolate', 'concentrate', 'blend'
  flavor: string,
  size: number, // en grammes
  servingSize: number,
  servingsPerContainer: number,
  nutritionFacts: {
    proteinPerServing: number,
    caloriesPerServing: number,
    fatPerServing: number,
    carbsPerServing: number,
    sugarPerServing: number
  },
  imageUrl: string,
  createdAt: timestamp,
  updatedAt: timestamp
}
```

### **Price**
```javascript
{
  id: string,
  productId: string,
  platform: 'myprotein' | 'prozis' | 'amazon' | 'bodybuilding',
  price: number,
  currency: 'EUR' | 'USD',
  url: string,
  inStock: boolean,
  lastChecked: timestamp,
  priceHistory: [
    {
      price: number,
      date: timestamp
    }
  ]
}
```

### **User** (optionnel, phase 2)
```javascript
{
  id: string,
  email: string,
  favorites: [productId],
  priceAlerts: [
    {
      productId: string,
      platform: string,
      targetPrice: number
    }
  ]
}
```

---

## ğŸš€ Feuille de Route (Roadmap)

### **Phase 1: Foundation (Semaines 1-2)**

#### Sprint 1.1 - Setup & Infrastructure
- [ ] Initialiser la structure backend (Express + PostgreSQL)
- [ ] Configurer Prisma/TypeORM pour l'ORM
- [ ] CrÃ©er les modÃ¨les de base de donnÃ©es
- [ ] Setup migrations
- [ ] Configurer les variables d'environnement
- [ ] CrÃ©er un Docker Compose pour dev (PostgreSQL + Redis)

#### Sprint 1.2 - API de Base
- [ ] CrÃ©er les routes CRUD pour Products
- [ ] CrÃ©er les routes CRUD pour Prices
- [ ] ImplÃ©menter la validation avec Zod
- [ ] Ajouter la documentation API (Swagger/OpenAPI)
- [ ] CrÃ©er des seeds de donnÃ©es pour le dÃ©veloppement

#### Sprint 1.3 - Frontend Foundation
- [ ] Installer et configurer React Router
- [ ] Installer TanStack Query
- [ ] Configurer les services API (axios)
- [ ] CrÃ©er le layout principal (Header, Footer, Navigation)
- [ ] ImplÃ©menter les pages de base (Home, ProductList)

---

### **Phase 2: Data Collection (Semaines 3-5)**

#### Sprint 2.1 - Infrastructure de Scraping
- [ ] CrÃ©er la classe `BaseScraper` abstraite
- [ ] ImplÃ©menter la gestion des proxies (optionnel)
- [ ] Configurer Puppeteer avec pool de navigateurs
- [ ] CrÃ©er un systÃ¨me de retry avec exponential backoff
- [ ] ImplÃ©menter le logging (Winston)

#### Sprint 2.2 - Scrapers Individuels
- [ ] **MyProtein Scraper**
  - Parser les pages produits
  - Extraire prix, images, nutritions
  - GÃ©rer la pagination
- [ ] **Prozis Scraper**
  - MÃªme approche
- [ ] **Amazon Scraper**
  - Attention aux dÃ©tections anti-bot
  - Utiliser l'API Product Advertising si possible

#### Sprint 2.3 - Queue & Automation
- [ ] Configurer Bull/BullMQ
- [ ] CrÃ©er les jobs de scraping
- [ ] ImplÃ©menter les cron jobs (mise Ã  jour quotidienne)
- [ ] Dashboard Bull Board pour monitoring
- [ ] SystÃ¨me d'alertes en cas d'Ã©chec

#### Sprint 2.4 - Data Matching
- [ ] Algorithme de matching de produits similaires
  - Comparaison de noms (fuzzy matching)
  - VÃ©rification de marque, taille, saveur
- [ ] SystÃ¨me de normalisation des donnÃ©es
- [ ] DÃ©tection de doublons

---

### **Phase 3: Core Features (Semaines 6-8)**

#### Sprint 3.1 - Product Display
- [ ] Page liste des produits avec filtres
  - Filtres: catÃ©gorie, marque, type, prix
  - Tri: prix, popularitÃ©, protÃ©ines/â‚¬
- [ ] Card produit avec infos essentielles
- [ ] SystÃ¨me de pagination ou infinite scroll
- [ ] Search bar avec autocomplÃ©tion

#### Sprint 3.2 - Product Detail Page
- [ ] Vue dÃ©taillÃ©e d'un produit
- [ ] Tableau comparatif des prix par plateforme
- [ ] Graphique d'historique des prix (Recharts)
- [ ] Informations nutritionnelles dÃ©taillÃ©es
- [ ] Bouton "Acheter" vers les plateformes

#### Sprint 3.3 - Comparison Feature
- [ ] SystÃ¨me de sÃ©lection multi-produits
- [ ] Page de comparaison cÃ´te Ã  cÃ´te
- [ ] Tableau comparatif (prix, nutrition, ratio protÃ©ines/â‚¬)
- [ ] Export en PDF (optionnel)
- [ ] Partage de comparaison via URL

#### Sprint 3.4 - Price Intelligence
- [ ] Calcul du "meilleur rapport qualitÃ©/prix"
  - Prix par kg de protÃ©ines
  - Score basÃ© sur nutrition + prix
- [ ] Badge "Meilleure offre" sur les cards
- [ ] Alertes de baisse de prix (email)

---

### **Phase 4: UX Enhancement (Semaines 9-10)**

#### Sprint 4.1 - Performance
- [ ] ImplÃ©menter le cache avec TanStack Query
- [ ] Lazy loading des images
- [ ] Code splitting par route
- [ ] Optimisation bundle size
- [ ] Service Worker pour offline (optionnel)

#### Sprint 4.2 - User Experience
- [ ] Dark mode
- [ ] Animations et transitions fluides
- [ ] Ã‰tats de chargement (skeletons)
- [ ] Gestion des erreurs utilisateur
- [ ] Toast notifications

#### Sprint 4.3 - Mobile Optimization
- [ ] Design responsive complet
- [ ] Touch gestures pour la comparaison
- [ ] Menu mobile optimisÃ©
- [ ] PWA capabilities

---

### **Phase 5: Advanced Features (Semaines 11-12)**

#### Sprint 5.1 - User Accounts (optionnel)
- [ ] Authentification (Supabase Auth ou JWT)
- [ ] Profil utilisateur
- [ ] Liste de favoris
- [ ] Historique de recherches

#### Sprint 5.2 - Price Alerts
- [ ] SystÃ¨me d'alertes email
- [ ] Configuration des seuils de prix
- [ ] Notifications push (optionnel)

#### Sprint 5.3 - Analytics & SEO
- [ ] IntÃ©gration Google Analytics
- [ ] Meta tags optimisÃ©s
- [ ] Sitemap dynamique
- [ ] Structured data (JSON-LD)

---

## ğŸ”§ DÃ©fis Techniques & Solutions

### **1. Scraping Challenges**

#### **Anti-Bot Detection**
- **ProblÃ¨me**: Sites protÃ©gÃ©s contre le scraping
- **Solutions**:
  - User-Agent rotation
  - Proxies rÃ©sidentiels (BrightData, Oxylabs)
  - Playwright avec empreintes browser rÃ©alistes
  - Rate limiting intelligent
  - Scraping pendant heures creuses

#### **Structure HTML Variable**
- **ProblÃ¨me**: Sites changent leur HTML
- **Solutions**:
  - SÃ©lecteurs CSS/XPath multiples (fallbacks)
  - Tests automatisÃ©s des scrapers
  - SystÃ¨me d'alertes si scraping Ã©choue
  - Documentation des selectors dans le code

#### **JavaScript Rendering**
- **ProblÃ¨me**: Contenu chargÃ© en JavaScript
- **Solutions**:
  - Puppeteer/Playwright (full browser)
  - Attente des Ã©lÃ©ments avec `waitForSelector`
  - Inspection des requÃªtes rÃ©seau (API directe)

### **2. Data Matching**

**Algorithme de Matching RecommandÃ©**:
```javascript
function matchProducts(product1, product2) {
  const similarity = {
    brand: product1.brand === product2.brand ? 1 : 0,
    name: stringSimilarity(product1.name, product2.name),
    size: Math.abs(product1.size - product2.size) < 100 ? 1 : 0,
    flavor: product1.flavor === product2.flavor ? 1 : 0
  };
  
  const score = 
    similarity.brand * 0.3 +
    similarity.name * 0.4 +
    similarity.size * 0.2 +
    similarity.flavor * 0.1;
  
  return score > 0.7; // Threshold
}
```

### **3. Performance**

- **Cache Redis**: 
  - Cache des prix pendant 1h
  - Cache des listes de produits pendant 24h
- **CDN**: Cloudflare pour images et assets
- **Database Indexing**: 
  - Index sur `brand`, `category`, `price`
- **Pagination API**: Limite 20-50 produits par page

---

## ğŸ“¦ Code Samples

### **Frontend: Product Card Component**

```jsx
// src/components/products/ProductCard.jsx
import { Link } from 'react-router-dom';
import { Card, CardContent, CardFooter } from '@/components/ui/card';
import { Badge } from '@/components/ui/badge';

export function ProductCard({ product, prices }) {
  const lowestPrice = Math.min(...prices.map(p => p.price));
  const bestPlatform = prices.find(p => p.price === lowestPrice);
  
  const pricePerKgProtein = (
    lowestPrice / 
    (product.nutritionFacts.proteinPerServing * product.servingsPerContainer / 1000)
  ).toFixed(2);

  return (
    <Card className="hover:shadow-lg transition-shadow">
      <CardContent className="p-4">
        <img 
          src={product.imageUrl} 
          alt={product.name}
          className="w-full h-48 object-cover rounded-md"
        />
        <h3 className="font-semibold mt-2 line-clamp-2">
          {product.name}
        </h3>
        <p className="text-sm text-gray-600">{product.brand}</p>
        
        <div className="flex gap-2 mt-2">
          <Badge variant="secondary">{product.type}</Badge>
          <Badge variant="outline">{product.size}g</Badge>
        </div>
      </CardContent>
      
      <CardFooter className="flex justify-between items-center">
        <div>
          <p className="text-2xl font-bold text-green-600">
            {lowestPrice.toFixed(2)}â‚¬
          </p>
          <p className="text-xs text-gray-500">
            {pricePerKgProtein}â‚¬/kg de protÃ©ines
          </p>
        </div>
        
        <Link 
          to={`/products/${product.id}`}
          className="btn-primary"
        >
          Comparer
        </Link>
      </CardFooter>
    </Card>
  );
}
```

### **Backend: Scraper Base Class**

```javascript
// scrapers/src/scrapers/base-scraper.js
import puppeteer from 'puppeteer';
import { logger } from '../utils/logger.js';

export class BaseScraper {
  constructor(platform) {
    this.platform = platform;
    this.browser = null;
    this.maxRetries = 3;
  }

  async init() {
    this.browser = await puppeteer.launch({
      headless: true,
      args: ['--no-sandbox', '--disable-setuid-sandbox']
    });
  }

  async close() {
    if (this.browser) {
      await this.browser.close();
    }
  }

  async scrapeWithRetry(url, scrapeFn, retries = this.maxRetries) {
    try {
      const page = await this.browser.newPage();
      await page.setUserAgent('Mozilla/5.0...');
      
      await page.goto(url, { waitUntil: 'networkidle2' });
      const result = await scrapeFn(page);
      
      await page.close();
      return result;
    } catch (error) {
      logger.error(`Scraping failed for ${url}`, error);
      
      if (retries > 0) {
        logger.info(`Retrying... (${retries} attempts left)`);
        await this.sleep(2000);
        return this.scrapeWithRetry(url, scrapeFn, retries - 1);
      }
      
      throw error;
    }
  }

  sleep(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  // Ã€ implÃ©menter par les scrapers enfants
  async scrapeProduct(url) {
    throw new Error('scrapeProduct must be implemented');
  }
}
```

### **Backend: MyProtein Scraper**

```javascript
// scrapers/src/scrapers/myprotein.js
import { BaseScraper } from './base-scraper.js';

export class MyProteinScraper extends BaseScraper {
  constructor() {
    super('myprotein');
    this.baseUrl = 'https://www.myprotein.fr';
  }

  async scrapeProduct(url) {
    return this.scrapeWithRetry(url, async (page) => {
      // Attendre le chargement du prix
      await page.waitForSelector('.productPrice_price');

      const product = await page.evaluate(() => {
        const name = document.querySelector('h1.productName')?.textContent.trim();
        const price = document.querySelector('.productPrice_price')?.textContent
          .replace('â‚¬', '').replace(',', '.').trim();
        const image = document.querySelector('.athenaProductImageCarousel_image img')?.src;
        
        // Extraire les infos nutritionnelles
        const nutritionTable = document.querySelector('.athenaProductNutrition_table');
        const proteinRow = Array.from(nutritionTable?.querySelectorAll('tr') || [])
          .find(row => row.textContent.includes('ProtÃ©ines'));
        const protein = proteinRow?.querySelector('td')?.textContent.trim();

        return {
          name,
          price: parseFloat(price),
          imageUrl: image,
          proteinPerServing: parseFloat(protein)
        };
      });

      return product;
    });
  }

  async scrapeCategory(categoryUrl) {
    const products = [];
    let page = 1;
    let hasMore = true;

    while (hasMore) {
      const url = `${categoryUrl}?page=${page}`;
      const pageProducts = await this.scrapeProductList(url);
      
      products.push(...pageProducts);
      hasMore = pageProducts.length > 0;
      page++;
    }

    return products;
  }

  async scrapeProductList(url) {
    return this.scrapeWithRetry(url, async (page) => {
      await page.waitForSelector('.productListProducts_product');

      const products = await page.evaluate(() => {
        const items = document.querySelectorAll('.productListProducts_product');
        return Array.from(items).map(item => ({
          name: item.querySelector('.productCard_productName')?.textContent.trim(),
          url: item.querySelector('a')?.href,
          price: parseFloat(
            item.querySelector('.productPrice_price')?.textContent
              .replace('â‚¬', '').replace(',', '.').trim()
          )
        }));
      });

      return products;
    });
  }
}
```

---

## ğŸ§ª Testing Strategy

### **Frontend Tests**
- **Unit**: Components avec Vitest + React Testing Library
- **Integration**: User flows avec Playwright
- **E2E**: ScÃ©narios critiques (recherche â†’ comparaison â†’ achat)

### **Backend Tests**
- **Unit**: Services et utilities avec Jest
- **Integration**: Routes API avec Supertest
- **Scrapers**: Mocked responses + tests sur des pages HTML statiques

---

## ğŸš¢ Deployment

### **Recommandation**

#### **Frontend**
- **Vercel** ou **Netlify** (dÃ©ploiement automatique depuis GitHub)
- Build optimisÃ© avec Vite
- Variables d'env pour l'API URL

#### **Backend**
- **Railway** ou **Render** (PostgreSQL inclus)
- Cron jobs pour scraping
- Redis pour cache

#### **Alternative Cloud**
- **AWS**: EC2 + RDS + ElastiCache + EventBridge (cron)
- **Google Cloud**: Cloud Run + Cloud SQL + Memorystore

---

## ğŸ“Š MÃ©triques de SuccÃ¨s

- **Performance**: Temps de chargement < 2s
- **Data Freshness**: Prix mis Ã  jour toutes les 24h
- **Coverage**: Au moins 3 plateformes scrapÃ©es
- **Accuracy**: 95%+ de matching correct entre produits
- **Uptime**: 99% pour l'API

---

## ğŸ”’ ConsidÃ©rations LÃ©gales

âš ï¸ **Important**: Le scraping peut violer les CGU des sites. ConsidÃ©rer:
- APIs officielles quand disponibles (Amazon Product API)
- Partenariats d'affiliation
- Rate limiting respectueux
- Mention lÃ©gale sur l'origine des donnÃ©es

---

## ğŸ“š Resources & Tools

### **Libraries ClÃ©s**
- **Frontend**: React Router, TanStack Query, Recharts, React Hook Form
- **Backend**: Express, Prisma, Bull, Puppeteer
- **Dev**: Vitest, Playwright, ESLint, Prettier

### **Services Externes**
- **Scraping Proxies**: BrightData, ScraperAPI
- **Email**: SendGrid, Resend
- **Monitoring**: Sentry, LogRocket

---

## ğŸ¯ Quick Start Commands

```bash
# Backend setup
cd backend
npm install
cp .env.example .env
npx prisma migrate dev
npm run seed
npm run dev

# Frontend setup
cd frontend
npm install
npm run dev

# Scrapers
cd scrapers
npm install
npm run scrape:myprotein
```

---

**Prochaines Ã©tapes recommandÃ©es:**
1. Setup du backend avec Prisma + PostgreSQL
2. CrÃ©ation du premier scraper (MyProtein)
3. API endpoint `/products` avec filtres
4. Interface produit de base avec React Query

Bonne chance avec Whey-Comparator! ğŸš€
